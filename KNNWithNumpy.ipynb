{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is for just understanding the implementations of KNN, for seeing more of **Exploratory Data Analysis** and **Data pre-processing** on the taken data please check the github repo for [logistic regression](https://github.com/Akshit2409/LogisticRegression/blob/master/LogisticRegressionUsingScikitLearn.ipynb) and to understand KNN properly please visit my [blog](https://medium.com/@akshit527/k-nearest-neighbors-k-nn-with-numpy-6c52cbe28093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I have not done much pre-processing the purpose of the code is to implement KNN with numpy\"\"\"\n",
    "#reading csv in dataframe\n",
    "df = pd.read_csv(\"seattleWeather_1948-2017.csv\")\n",
    "#removing null values\n",
    "df.dropna(axis=0,inplace=True)\n",
    "#reset the index as the rows with null values are removed \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#create a variable to store the labels\n",
    "label = df['RAIN'].replace([False,True],[0,1])\n",
    "#dropping the date and label column as date is not helping in classification and Rain is our label\n",
    "df.drop(['RAIN','DATE'],axis=1,inplace=True)\n",
    "#splitting the data in train(75%) and test(25%)\n",
    "train_df, test_df, train_label, test_label = (df[0:int(0.75*len(df))], df[int(0.75*len(df)):], label[0:int(0.75*len(label))], label[int(0.75*len(label)):])\n",
    "train_df, test_df, train_label, test_label = np.array(train_df), np.array(test_df), np.array(train_label), np.array(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function for KNN\n",
    "def KNN(x,y,k):\n",
    "    dist = []\n",
    "    #calculate euclidean distance\n",
    "    dist_ind = np.sqrt(np.sum((x-y)**2, axis=1))\n",
    "    #adding labels of training data to the distance array\n",
    "    main_arr = np.column_stack((train_label,dist_ind))\n",
    "    #sorting the distances in ascending order along with labels\n",
    "    main = main_arr[main_arr[:,1].argsort()]\n",
    "    #finding the count of K neighbors\n",
    "    count = Counter(main[0:k,0])\n",
    "    #Returning the label based on the count\n",
    "    keys, vals = list(count.keys()), list(count.values())\n",
    "    if len(vals)>1:\n",
    "        if vals[0]>vals[1]:\n",
    "            return int(keys[0])\n",
    "        else:\n",
    "            return int(keys[1])\n",
    "    else:\n",
    "        return int(keys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     11646\n",
      "           1       0.91      0.99      0.95      7515\n",
      "\n",
      "    accuracy                           0.96     19161\n",
      "   macro avg       0.95      0.96      0.96     19161\n",
      "weighted avg       0.96      0.96      0.96     19161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#since it is a non-parametric method, which is there is no weights we just calculate the nearest distance, so no need to do training\n",
    "pred = []\n",
    "for i in range(len(train_df)):\n",
    "    pred.append(KNN(train_df,train_df[i],5))\n",
    "#Checking the classification report\n",
    "print(classification_report(pred, train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3973\n",
      "           1       0.87      0.98      0.92      2414\n",
      "\n",
      "    accuracy                           0.94      6387\n",
      "   macro avg       0.93      0.95      0.93      6387\n",
      "weighted avg       0.94      0.94      0.94      6387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = []\n",
    "for i in range(len(test_df)):\n",
    "    test_pred.append(KNN(train_df,test_df[i],5))\n",
    "print(classification_report(test_pred, test_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
